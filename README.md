# Entropy vs self sequence alignment
Entropy vs self sequence alignment (aka INFORMATION ENTROPY)....

Information entropy (IE) and Information content (IC) are two methods that quantitatively measure information. Information entropy provides a measure of the average amount of information that is needed to represent an event drawn from a probability distribution for a random variable. The results provided by information entropy are compared in parallel with the results provided by the information content model (self-sequence alignment). This comparison is made to highlight the qualitative differences between information entropy and the new method of information content described as a primary source in [this work](https://books.google.ro/books?id=y1I5EAAAQBAJ&printsec=frontcover&source=gbs_ge_summary_r&cad=0#v=onepage&q&f=false).

# Live demo

https://gagniuc.github.io/Entropy-vs-self-sequence-alignment/

# Screenshot

<kbd><img src="https://github.com/Gagniuc/Entropy-vs-self-sequence-alignment/blob/main/Entropy%20vs%20self%20sequence%20alignment.png" /></kbd>

# References

<i>Paul A. Gagniuc. Algorithms in Bioinformatics: Theory and Implementation. John Wiley & Sons, Hoboken, NJ, USA, 2021, ISBN: 9781119697961.</i>
